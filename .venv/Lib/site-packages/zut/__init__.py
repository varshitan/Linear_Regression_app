"""
Reusable Python utilities (top-level API).
"""
from __future__ import annotations

import atexit
import csv
import ctypes
import inspect
import json
import locale
import logging
import logging.config
import os
import re
import socket
import sys
import unicodedata
from argparse import ArgumentParser, RawTextHelpFormatter, _SubParsersAction
from configparser import _UNSET, ConfigParser, RawConfigParser
from contextlib import nullcontext
from datetime import date, datetime, time, timedelta, timezone, tzinfo
from decimal import Decimal
from enum import Enum, Flag
from http.client import HTTPResponse
from importlib import import_module
from importlib.util import find_spec
from io import BufferedIOBase, IOBase, StringIO, TextIOBase, TextIOWrapper
from ipaddress import AddressValueError, IPv4Address, IPv6Address, ip_address
from pathlib import Path
from subprocess import CompletedProcess, SubprocessError
from textwrap import dedent
from threading import Thread
from traceback import format_exception
from types import FunctionType, ModuleType, TracebackType
from typing import (TYPE_CHECKING, Any, Callable, Iterable, MutableMapping,
                    TypeVar, overload)
from urllib.error import HTTPError, URLError
from urllib.parse import quote, urlencode, urlparse, urlunparse
from urllib.request import Request, urlopen
from uuid import UUID

try:
    from typing import Literal
except ImportError:
    # Literal was introduced in Python 3.8
    from typing_extensions import Literal

if TYPE_CHECKING:
    # In order to optimize, we don't want to import the entire zut.db and zut.excel modules during normal execution
    from zut.db import DbAdapter
    from zut.excel import ExcelTable

# ----- Optional dependencies -----
try:
    from zoneinfo import ZoneInfo
except ImportError:
    # ZoneInfo was introduced in Python 3.9
    ZoneInfo = None

try:
    import tzdata

    # Used to parse timezones from strings through ZoneInfo on Windows (Windows does not maintain a database of timezones)
except ImportError:
    tzdata = None

try:
    import tzlocal
    # Used to parse timezones from strings on Windows (Windows does not maintain a database of timezones and `tzdata` only is not enough)
except ImportError:
    tzlocal = None

try:
    import pytz
    # Used to parse timezones on Python < 3.9 (no ZoneInfo available)
except ImportError:
    pytz = None

try:
    import colorlog
except ImportError:
    colorlog = None

try:
    from tabulate import tabulate
except ImportError:
    tabulate = None

try:
    from django.utils.functional import Promise
except ImportError:
    Promise = None

__prog__ = 'zut'

try:
    # Version generated by setuptools_scm during build
    from ._version import __version__, __version_tuple__
except ImportError:
    __version__ = None
    __version_tuple__ = None

ZUT_ROOT = Path(__file__).resolve().parent

logger = logging.getLogger(__name__)

T = TypeVar('T')


#region Text

def slugify(value: str, separator: str = '-', keep: str = None, strip_separator: bool = True, strip_keep: bool = True, if_none: str = None) -> str:
    """ 
    Generate a slug.
    """
    if value is None:
        return if_none
    
    separator = separator if separator is not None else ''
    keep = keep if keep is not None else ''

    # Normalize the string: replace diacritics by standard characters, lower the string, etc
    value = str(value)
    value = unicodedata.normalize("NFKD", value).encode("ascii", "ignore").decode("ascii")
    value = value.lower()

    # Remove special characters
    remove_sequence = r'^a-zA-Z0-9\s' + re.escape(separator) + re.escape(keep)
    value = re.sub(f"[{remove_sequence}]", "", value)

    # Replace spaces and successive separators by a single separator
    replace_sequence = r'\s' + re.escape(separator)
    value = re.sub(f"[{replace_sequence}]+", separator, value)
    
    # Strips separator and kept characters
    strip_chars = (separator if strip_separator else '') + (keep if strip_keep else '')
    value = value.strip(strip_chars)

    return value


def slugify_django(value: str) -> str:
    """ 
    Generate a slug, same as `django.utils.text.slugify`.
    """
    return slugify(value, separator='-', keep='_', strip_separator=True, strip_keep=True, if_none='none')


def slugify_snake(value: str, separator: str = '_', if_none: str = None) -> str:
    """
    CamÃ¨lCase => camel_case
    """
    if value is None:
        return if_none
    
    separator = separator if separator is not None else ''
    
    # Normalize the string: replace diacritics by standard characters, etc
    # NOTE: don't lower the string
    value = str(value)
    value = unicodedata.normalize("NFKD", value).encode("ascii", "ignore").decode("ascii")
    
    value = re.sub(r"[^\w\s-]", "", value)
    value = re.sub(r"[-_\s]+", separator, value).strip(separator)
    value = re.sub(r'(.)([A-Z][a-z]+)', f'\\1{separator}\\2', value)
    return re.sub(r'([a-z0-9])([A-Z])', f'\\1{separator}\\2', value).lower()


def skip_utf8_bom(fp: TextIOWrapper|BufferedIOBase):
    """
    Skip UTF8 byte order mark, if any.
    """
    data = fp.read(1)
    
    if isinstance(data, str): # text mode
        if len(data) >= 1 and data[0] == UTF8_BOM:
            return True
        
    elif isinstance(data, bytes): # binary mode
        if len(data) >= 1 and data[0] == UTF8_BOM_BINARY[0]:
            data += fp.read(2)
            if data[0:3] == UTF8_BOM_BINARY:
                return True
    
    fp.seek(0)
    return False


UTF8_BOM = '\ufeff'
UTF8_BOM_BINARY = UTF8_BOM.encode('utf-8')


def parse_uuid_or_none(uuid: str, version: int = None):
    """
    Check if the given string is a valid UUID, if yes, return the `UUID` object, otherwise return `None`.
    """    
    try:
        return UUID(uuid, version=version)
    except ValueError:
        return None


def parse_ipaddress_or_none(address: str, version: int = None):
    """
    Check if the given string is a valid IP address, if yes, return the `IPv4Address` or `IPv6Address` object, otherwise return `None`.
    """    
    try:
        ip = ip_address(address)
    except ValueError:
        return False
    
    if version is None or ip.version == version:
        return ip
    else:
        return None


class Filter:
    def __init__(self, spec: str|re.Pattern, *, normalize: bool = False):
        self.normalize = normalize

        if isinstance(spec, re.Pattern):
            self.regex = spec

        elif isinstance(spec, str) and spec.startswith('^'):
            m = re.match(r'^(.*\$)(A|I|L|U|M|S|X)+$', spec, re.IGNORECASE)
            if m:
                pattern = m[1]
                flags = re.NOFLAG
                for letter in m[2]:
                    flags |= re.RegexFlag[letter.upper()]
            else:
                pattern = spec
                flags = re.NOFLAG

            self.regex = re.compile(pattern, flags)

        elif isinstance(spec, str):
            if self.normalize:
                spec = self.normalize_spec(spec)

            if '*' in spec:
                name_parts = spec.split('*')
                pattern_parts = [re.escape(name_part) for name_part in name_parts]
                pattern = r'^' + r'.*'.join(pattern_parts) + r'$'
                self.regex = re.compile(pattern)
            else:
                self.regex = spec

        else:
            raise TypeError(f"filter spec must be a string or regex pattern, got {type(spec).__name__}")
       

    def __repr__(self) -> str:
        return self.regex.pattern if isinstance(self.regex, re.Pattern) else self.regex


    def matches(self, value: str, is_normalized: bool = False):
        if value is None:
            value = ""
        elif not isinstance(value, str):
            value = str(value)

        if self.normalize and not is_normalized:
            value = self.normalize_value(value)

        if isinstance(self.regex, re.Pattern):
            if self.regex.match(value):
                return True
            
        elif self.regex == value:
            return True


    @classmethod
    def normalize_spec(cls, spec: str):
        return slugify(spec, separator=None, keep='*', strip_keep=False, if_none=None)
    
    
    @classmethod
    def normalize_value(cls, value: str):
        return slugify(value, separator=None, keep=None, if_none=None)


class Filters:
    def __init__(self, specs: list[str|re.Pattern]|str|re.Pattern, *, normalize: bool = False):
        self.filters: list[Filter] = []

        if specs:
            if isinstance(specs, (str,re.Pattern)):
                specs = [specs]

            for spec in specs:
                self.filters.append(Filter(spec, normalize=normalize))


    def __len__(self):
        return len(self.filters)


    def matches(self, value: str, if_no_filter: bool = False):
        if not self.filters:
            return if_no_filter
        
        if value is None:
            value = ""
        elif not isinstance(value, str):
            value = str(value)
        
        normalized_value = None    

        for str_filter in self.filters:
            if str_filter.normalize:
                if normalized_value is None:
                    normalized_value = Filter.normalize_value(value)
                if str_filter.matches(normalized_value, is_normalized=True):
                    return True
            else:
                if str_filter.matches(value):
                    return True
                
        return False

#endregion


#region Numbers

def gigi_bytes(value: int) -> float:
    """
    Convert from bytes to GigiBytes.

    See: https://simple.wikipedia.org/wiki/Gibibyte
    """
    if value is None:
        return None
    return value / 1024**3


def megi_bytes(value: int) -> float:
    """
    Convert from bytes to MegiBytes.

    See: https://simple.wikipedia.org/wiki/Mebibyte
    """
    if value is None:
        return None
    return value / 1024**2


def kili_bytes(value: int) -> float:
    """
    Convert from bytes to KiliBytes.

    See: https://simple.wikipedia.org/wiki/Kibibyte
    """
    if value is None:
        return None
    return value / 1024


def human_bytes(value: int, *, unit: str = 'iB', divider: int = 1024, decimals: int = 1, max_multiple: str = None) -> str:
    """
    Get a human-readable representation of a number of bytes.
    
    :param max_multiple: may be `K`, `M`, `G` or `T`.
    """
    return human_number(value, unit=unit, divider=divider, decimals=decimals, max_multiple=max_multiple)


def human_number(value: int, *, unit: str = '', divider: int = 1000, decimals: int = 1, max_multiple: str = None) -> str:
    """
    Get a human-readable representation of a number.

    :param max_multiple: may be `K`, `M`, `G` or `T`.
    """
    if value is None:
        return None

    suffixes = []

    # Append non-multiple suffix (bytes)
    # (if unit is 'iB' we dont display the 'i' as it makes more sens to display "123 B" than "123 iB")
    if unit:
        suffixes.append(' ' + (unit[1:] if len(unit) >= 2 and unit[0] == 'i' else unit))
    else:
        suffixes.append('')

    # Append multiple suffixes
    for multiple in ['K', 'M', 'G', 'T']:
        suffixes.append(f' {multiple}{unit}')
        if max_multiple and max_multiple.upper() == multiple:
            break

    i = 0
    suffix = suffixes[i]
    divided_value = value

    while divided_value > 1000 and i < len(suffixes) - 1:
        divided_value /= divider
        i += 1
        suffix = suffixes[i]

    # Format value
    formatted_value = locale.format_string('%d' if i == 0 else f'%.{decimals}f', divided_value, grouping=True)
    
    # Display formatted value with suffix
    return f'{formatted_value}{suffix}'

#endregion


#region Convert

@overload
def convert(value: Any, to: type[T], *, nullval = None, if_none = None) -> T:
    ...

def convert(value: Any, to: type[T]|Callable, *, nullval = None, if_none = None):
    if value == nullval:
        return None
    
    if not isinstance(to, type):
        return to(value)
    
    if isinstance(value, to):
        return value
    
    if value is None:
        return if_none
    
    strvalue = str(value)

    if to == str:
        return strvalue
    
    elif to == bool:
        lower = strvalue.lower()
        if lower not in RawConfigParser.BOOLEAN_STATES:
            raise ValueError('Not a boolean: %s' % strvalue)
        return RawConfigParser.BOOLEAN_STATES[lower]

    elif to == float or to == Decimal:
        return to(strvalue.replace(',', '.'))
    
    elif to == datetime or to == date or to == time:
        return to.fromisoformat(strvalue)
    
    elif to == list:
        strvalue = strvalue.strip()
        if not strvalue:
            return []
        return re.split(r'[\W,;|]+', strvalue)
    
    else:
        return to(strvalue)


def convert_to_bool(value: Any, *, nullval = None, if_none = None):
    return convert(value, bool, nullval=nullval, if_none=if_none)


def convert_to_int(value: Any, *, nullval = None, if_none = None):
    return convert(value, int, nullval=nullval, if_none=if_none)


def convert_to_decimal(value: Any, *, nullval = None, if_none = None):
    return convert(value, Decimal, nullval=nullval, if_none=if_none)


def convert_to_date(value: Any, *, nullval = None, if_none = None):
    return convert(value, date, nullval=nullval, if_none=if_none)


def convert_to_datetime(value: Any, *, nullval = None, if_none = None):
    return convert(value, datetime, nullval=nullval, if_none=if_none)


def convert_str_args(func: Callable, *args: str):
    if not args:
        return tuple(), dict()
    
    # Determine argument types
    signature = inspect.signature(func)
    var_positional_type = None
    var_keyword_type = None
    parameter_types = {}
    positional_types = []
    for parameter in signature.parameters.values():
        parameter_type = None if parameter.annotation is inspect.Parameter.empty else parameter.annotation
        if parameter.kind == inspect.Parameter.VAR_POSITIONAL:
            var_positional_type = parameter_type
        elif parameter.kind == inspect.Parameter.VAR_KEYWORD:
            var_keyword_type = parameter_type
        else:
            parameter_types[parameter.name] = parameter_type
            if parameter.kind in [inspect.Parameter.POSITIONAL_ONLY, inspect.Parameter.POSITIONAL_OR_KEYWORD]:
                positional_types.append(parameter_type)
    
    # Distinguish args and kwargs
    positionnal_args = []
    keyword_args = {}
    for arg in args:
        m = re.match(r'^([a-z0-9_]+)=(.+)$', arg)
        if m:
            keyword_args[m[1]] = m[2]
        else:
            positionnal_args.append(arg)

    # Convert kwargs
    for parameter, value in keyword_args.items():
        if parameter in parameter_types:
            target_type = parameter_types[parameter]
            if target_type:
                keyword_args[parameter] = convert(value, target_type)

        elif var_keyword_type:
            keyword_args[parameter] = convert(value, var_keyword_type)

    # Convert args
    for i, value in enumerate(positionnal_args):
        if i < len(positional_types):
            target_type = positional_types[i]
            if target_type:
                positionnal_args[i] = convert(value, target_type)

        elif var_positional_type:
            positionnal_args[i] = convert(value, var_positional_type)

    return positionnal_args, keyword_args

#endregion


#region CSV

def dump_to_csv(out: os.PathLike|IOBase, data: Iterable[Iterable|dict], *, headers: list[str|Header] = None, encoding: str = 'utf-8-sig', csv_decimal_separator: str = None, csv_delimiter: str = None, csv_quotechar: str = None, csv_nullval: str = None, **params):
    """
    Dump a list of dicts or iterables to CSV.
    """
    with out_table(out, tablefmt='csv', headers=headers, encoding=encoding, csv_decimal_separator=csv_decimal_separator, csv_delimiter=csv_delimiter, csv_quotechar=csv_quotechar, csv_nullval=csv_nullval, **params) as t:
        for row in data:
            t.append(row)


def iter_dicts_from_csv(file: os.PathLike|IOBase, *, headers: list[str|Header] = None, encoding: str = 'utf-8', noheaders: bool = False, csv_delimiter: str = None, csv_quotechar: str = None, csv_nullval: str = None):
    """
    Iterate over CSV as dicts.
    """    
    from zut import files

    if noheaders and not headers:
        raise ValueError("Headers must be given has an argument if CSV file does not contain headers.")

    header_indices: dict[Header,int] = None

    with nullcontext(file) if isinstance(file, IOBase) else files.open(file, 'r', newline='', encoding=encoding) as fp:
        _, csv_delimiter, csv_quotechar, csv_nullval = _get_csv_params(None, csv_delimiter, csv_quotechar, csv_nullval, context=fp)

        if encoding == 'utf-8':
            skip_utf8_bom(fp)

        reader = csv.reader(fp, delimiter=csv_delimiter, quotechar=csv_quotechar)
        next_is_header = False if noheaders else True
        for n, row in enumerate(reader):
            if next_is_header:
                next_is_header = False
                actual_header_names = [name for name in row]
                header_indices = _get_header_indices(actual_header_names, headers)

            else:
                data = {}
                for header, index in header_indices.items():
                    if index >= len(row):
                        raise ValueError(f"Cannot read column {index+1} ({header}) at row {n+1} ({len(row)} columns)")
                    value = row[index]

                    if value == csv_nullval:
                        value = None
                    else:
                        value = header.convert(value)
                    data[header.name] = value

                yield data

        if isinstance(file, IOBase):
            file.seek(0)


def get_dicts_from_csv(file: os.PathLike|IOBase, *, headers: list[str|Header] = None, encoding: str = 'utf-8', noheaders: bool = False, csv_delimiter: str = None, csv_quotechar: str = None, csv_nullval: str = None):
    """
    Load CSV as a dict list.
    """
    return [row for row in iter_dicts_from_csv(file, headers=headers, encoding=encoding, noheaders=noheaders, csv_delimiter=csv_delimiter, csv_quotechar=csv_quotechar, csv_nullval=csv_nullval)]


def get_csv_headers(file: os.PathLike|IOBase, *, encoding: str = 'utf-8', csv_delimiter: str = None, csv_quotechar: str = None) -> list[Header]:
    from zut import files

    with nullcontext(file) if isinstance(file, IOBase) else files.open(file, 'r', newline='', encoding=encoding) as fp:
        _, csv_delimiter, csv_quotechar, _ = _get_csv_params(None, csv_delimiter, csv_quotechar, None, context=fp)
        
        if encoding == 'utf-8':
            skip_utf8_bom(fp)

        reader = csv.reader(fp, delimiter=csv_delimiter, quotechar=csv_quotechar)
        try:
            result = [Header(name) for name in next(reader)]
        except StopIteration:
            result = None

        if isinstance(file, IOBase):
            file.seek(0)

        return result


def _get_header_indices(actual_header_names: list[str], headers: list[str|Header] = None) -> dict[Header,int]:
    if not headers:
        return {Header(name): index for index, name in enumerate(actual_header_names)}

    elif '*' in headers:
        headers_by_name: dict[str,Header] = {}
        missing_header_names = []
        for header in headers:
            if header == '*':
                continue
            if not isinstance(header, Header):
                header = Header(header)
            if not header.name in actual_header_names:
                missing_header_names.append(header.name)
            headers_by_name[header.name] = header

        if missing_header_names:
            raise ValueError(f"Header not found: {', '.join(missing_header_names)}")
        
        header_indices = {}
        for index, name in enumerate(actual_header_names):
            header = headers_by_name.get(name)
            if header is None:
                header = Header(name)
            header_indices[header] = index
        return header_indices

    else:
        header_indices = {}
        missing_header_names = []
        for header in headers:
            if not isinstance(header, Header):
                header = Header(header)
            try:
                index = actual_header_names.index(header.name)
                header_indices[header] = index
            except ValueError:
                missing_header_names.append(header.name)
        
        if missing_header_names:
            raise ValueError(f"Header not found: {', '.join(missing_header_names)}")
        return header_indices


def _is_semicolon_csv(file: TextIOBase|os.PathLike):
    """
    Guess if the given CSV file is delimited by semicolons.
    """
    from zut import files

    with nullcontext(file) if isinstance(file, IOBase) else files.open(file, 'r', encoding='utf-8') as fp:
        text: str = fp.read(1000)
        try:
            pos = text.index('\n')
            line = text[0:pos]
        except ValueError:
            line = text

        result = ';' in line
        fp.seek(0)
        return result


def _get_csv_params(csv_decimal_separator: str|None, csv_delimiter: str|None, csv_quotechar: str|None, csv_nullval: str|None, *, context: Literal['csv-excel','csv']|TextIOBase|os.PathLike):
    _context_defaults = []

    def get_context_defaults():
        if not _context_defaults:
            if context == 'csv-excel':
                decimal_separator = get_locale_decimal_point()
                delimiter = ';' if decimal_separator == ',' else ','
            elif context == 'csv':
                decimal_separator = '.'
                delimiter = ','
            else:
                if csv_delimiter == ';' or _is_semicolon_csv(context):
                    decimal_separator = ','
                    delimiter = ';'
                else:
                    decimal_separator = '.'
                    delimiter = ','

            _context_defaults.append(decimal_separator)
            _context_defaults.append(delimiter)
        return _context_defaults[0], _context_defaults[1]


    if csv_decimal_separator is None:
        csv_decimal_separator, _ = get_context_defaults()
        
    if csv_delimiter is None:
        _, csv_delimiter = get_context_defaults()

    csv_quotechar = csv_quotechar if csv_quotechar is not None else '"'
    csv_nullval = csv_nullval if csv_nullval is not None else ''

    return csv_decimal_separator, csv_delimiter, csv_quotechar, csv_nullval


#endregion


#region JSON
    
class ExtendedJSONEncoder(json.JSONEncoder):
    """
    Adapted from: django.core.serializers.json.DjangoJSONEncoder
    
    Usage example: json.dumps(data, indent=4, cls=ExtendedJSONEncoder)
    """
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def default(self, o):
        if isinstance(o, datetime):
            r = o.isoformat()
            if o.microsecond and o.microsecond % 1000 == 0:
                r = r[:23] + r[26:]
            if r.endswith("+00:00"):
                r = r[:-6] + "Z"
            return r
        elif isinstance(o, date):
            return o.isoformat()
        elif isinstance(o, time):
            if o.tzinfo is not None:
                raise ValueError("JSON can't represent timezone-aware times.")
            r = o.isoformat()
            if o.microsecond and o.microsecond % 1000 == 0:
                r = r[:12]
            return f'T{r}'
        elif isinstance(o, timedelta):
            return duration_iso_string(o)
        elif isinstance(o, (Decimal, UUID)):
            return str(o)
        elif Promise and isinstance(o, Promise):
            return str(o)
        elif isinstance(o, (Enum,Flag)):
            return o.name
        else:
            return super().default(o)

#endregion


#region Locale

def register_locale(value: str = '', *, use_excel_csv: bool = True):
    """
    Register locale (default locale if argument `value` is None).

    - `use_excel_csv`: if True, use Excel-compatible version of CSV (which is localized) in OutTable by default.
    """
    lang, encoding = locale.getlocale(locale.LC_NUMERIC)
    if lang:
        logger.warning("Locale already set: lang=%s, encoding=%s", lang, encoding)

    locale.setlocale(locale.LC_ALL, value)
    if use_excel_csv:
        OutTable.DEFAULT_CSV_FMT = 'csv-excel'


def is_locale_registered(warn = False):
    lang, encoding = locale.getlocale(locale.LC_NUMERIC)
    if lang and warn:
        logger.warning("Locale already set: lang=%s, encoding=%s", lang, encoding)
    return lang is not None


_decimal_point = None

def get_locale_decimal_point() -> str:
    global _decimal_point

    if _decimal_point is not None:
        return _decimal_point
    
    if not is_locale_registered():
        register_locale()
    
    _decimal_point = locale.localeconv()['decimal_point']
    return _decimal_point

#endregion


#region Time

T_WithTime = TypeVar('T_WithTime', datetime, time)

def parse_tz(tz: tzinfo|str|Literal['localtime']|None = None, *, explicit_local = False):
    if tz is None or tz == 'localtime':
        if explicit_local:
            if not ZoneInfo or sys.platform == 'win32':
                if not tzlocal:
                    raise ValueError(f"Package `tzlocal` is required on Windows or on Python < 3.9 to retrieve local timezone")
                return tzlocal.get_localzone()
            return ZoneInfo('localtime')
        else:
            return None
    elif isinstance(tz, tzinfo):
        return tz
    elif tz == 'UTC':
        return timezone.utc
    elif isinstance(tz, str):
        if not ZoneInfo:
            if not pytz:
                raise ValueError(f"Package `pytz` is required on Python < 3.9 to parse timezones from strings")
            return pytz.timezone(tz)
        if sys.platform == 'win32':
            if not tzdata:
                raise ValueError(f"Package `tzdata` is required on Windows to parse timezones from strings")
        return ZoneInfo(tz)
    else:
        raise TypeError(f"Invalid timezone type: {tz} ({type(tz).__name__})")


def is_aware(value: T_WithTime):
    # See: https://docs.python.org/3/library/datetime.html#determining-if-an-object-is-aware-or-naive
    if value is None:
        return False
    return value.tzinfo is not None and value.utcoffset() is not None


def now_aware(tz: tzinfo|str = None, *, ms = True):
    """
    Get the current datetime in the timezone `tz` (use `tz=None` or `tz='localtime'` for the system local timezone).
    """
    now = datetime.now().astimezone(parse_tz(tz))
    if not ms:
        now = now.replace(microsecond=0)
    return now


def make_aware(value: T_WithTime, tz: tzinfo|str = None) -> T_WithTime:
    """
    Make a datetime aware in timezone `tz` (use `tz=None` or `tz='localtime'` for the system local timezone).
    """
    if value is None:
        return None
    if is_aware(value):
        raise ValueError("make_aware expects a naive datetime, got %s" % value)
    
    tz = parse_tz(tz, explicit_local=True)
    if hasattr(tz, 'localize'):
        # See: https://stackoverflow.com/a/6411149
        return tz.localize(value)
    else:
        return value.replace(tzinfo=tz)


def is_naive(value: T_WithTime):
    return not is_aware(value)


def make_naive(value: T_WithTime, tz: tzinfo = None) -> T_WithTime:
    """
    Make a datetime naive and expressed in timezone `tz` (use `tz=None` or `tz='localtime'` for the system local timezone).
    """
    if value is None:
        return None
    if not is_aware(value):
        raise ValueError("make_naive expects an aware datetime, got %s" % value)
    
    value = value.astimezone(parse_tz(tz))
    value = value.replace(tzinfo=None)
    return value


def duration_iso_string(duration: timedelta):
    # Adapted from: django.utils.duration.duration_iso_string
    if duration < timedelta(0):
        sign = "-"
        duration *= -1
    else:
        sign = ""

    days, hours, minutes, seconds, microseconds = _get_duration_components(duration)
    ms = ".{:06d}".format(microseconds) if microseconds else ""
    return "{}P{}DT{:02d}H{:02d}M{:02d}{}S".format(
        sign, days, hours, minutes, seconds, ms
    )


def _get_duration_components(duration: timedelta):
    days = duration.days
    seconds = duration.seconds
    microseconds = duration.microseconds

    minutes = seconds // 60
    seconds = seconds % 60

    hours = minutes // 60
    minutes = minutes % 60

    return days, hours, minutes, seconds, microseconds


_today = None

def today():
    global _today
    if _today is None:    
        _today = datetime.today().date()
    return _today

#endregion


#region URLs


def build_url(*, scheme: str = '', hostname: str|IPv4Address|IPv6Address = None, port: int = None, username: str = None, password: str = None, path: str = None, params: str = None, query: str = None, fragment: str = None, noquote = False, hide_password = False):
    netloc = build_netloc(hostname=hostname, port=port, username=username, password=password, noquote=noquote, hide_password=hide_password)

    if noquote:
        actual_query = query
    else:
        if isinstance(query, dict):
            actual_query = urlencode(query)
        elif isinstance(query, list):
            named_parts = []
            unnamed_parts = []
            for part in query:
                if isinstance(part, tuple):
                    named_parts.append(part)
                else:
                    unnamed_parts.append(part)
            actual_query = urlencode(named_parts, quote_via=quote)
            actual_query += ('&' if actual_query else '') + '&'.join(quote(part) for part in unnamed_parts)
        else:
            actual_query = query

    return urlunparse((scheme or '', netloc or '', (path or '') if noquote else quote(path or ''), (params or '') if noquote else quote(params or ''), actual_query or '', (fragment or '') if noquote else quote(fragment or '')))


def build_netloc(*, hostname: str|IPv4Address|IPv6Address = None, port: int = None, username: str = None, password: str = None, noquote = False, hide_password = False):
    netloc = ''
    if username or hostname:
        if username:
            netloc += username if noquote else quote(username)
            if password:
                netloc += ':' + ('***' if hide_password else (password if noquote else quote(password)))
            netloc += '@'

        if hostname:
            if isinstance(hostname, IPv4Address):
                netloc += hostname.compressed
            elif isinstance(hostname, IPv6Address):
                netloc += f"[{hostname.compressed}]"
            else:
                ipv6 = None
                if ':' in hostname:
                    try:
                        ipv6 = IPv6Address(hostname)
                    except AddressValueError:
                        pass

                if ipv6:
                    netloc += f"[{ipv6.compressed}]"
                else:
                    netloc += hostname if noquote else quote(hostname)

            if port:
                if not isinstance(port, int):
                    raise ValueError(f"invalid type for port: {type(port)}")
                netloc += f':{port}'

    return netloc


def hide_url_password(url: str):
    r = urlparse(url)
    return build_url(scheme=r.scheme, hostname=r.hostname, port=r.port, username=r.username, password=r.password, path=r.path, params=r.params, query=r.query, fragment=r.fragment, noquote=True, hide_password=True)


#endregion


#region Network

def resolve_host(host: str, *, timeout: float = None, ip_version: int = None) -> list[str]:
    """
    Make a DNS resolution with a timeout.
    """
    ip = parse_ipaddress_or_none(host)
    if ip:
        return [ip.compressed]
    
    if ip_version is None:
        family = 0
    elif ip_version == 4:
        family = socket.AddressFamily.AF_INET
    elif ip_version == 6:
        family = socket.AddressFamily.AF_INET6
    else:
        raise ValueError(f"Invalid ip version: {ip_version}")

    class Bucket:
        addresses = []
        exception = None

    bucket = Bucket()

    def target():
        try:
            for af, socktype, proto, canonname, sa in socket.getaddrinfo(host, port=0, family=family):
                bucket.addresses.append(sa[0])
        except BaseException as err:
            bucket.exception = err

    if timeout is not None:
        thread = Thread(target=target, daemon=True)
        thread.start()
        thread.join(timeout=timeout)
        if thread.is_alive():
            raise TimeoutError(f"Name resolution for host \"{host}\" timed out")

    else:
        target()

    if bucket.exception:
        err = NameError(str(bucket.exception))
        err.name = host
        raise err
        
    return bucket.addresses


class JSONApiClient:
    base_url : str = None
    timeout: float = None
    """ Timeout in seconds. """

    force_trailing_slash: bool = False

    default_headers = {
        'Content-Type': 'application/json; charset=utf-8',
        'Accept': 'application/json; charset=utf-8',
    }

    json_encoder_cls: type[json.JSONEncoder] = ExtendedJSONEncoder
    json_decoder_cls: type[json.JSONDecoder] = json.JSONDecoder
    
    nonjson_error_maxlen = 400


    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs) # necessary to allow this class to be used as a mixin
        self.logger = logging.getLogger(type(self).__module__ + '.' + type(self).__name__)


    def __enter__(self):
        return self


    def __exit__(self, exc_type = None, exc_value = None, exc_traceback = None):
        pass


    def get(self, endpoint: str = None, *, params: dict = None, headers: MutableMapping[str,str] = None, return_headers = False):
        return self.request(endpoint, method='GET', params=params, headers=headers, return_headers=return_headers)


    def post(self, endpoint: str = None, data = None, *, params: dict = None, headers: MutableMapping[str,str] = None, return_headers = False, content_type: str = None, content_length: int = None, content_filename: str = None):
        return self.request(endpoint, data, method='POST', params=params, headers=headers, return_headers=return_headers, content_type=content_type, content_length=content_length, content_filename=content_filename)
    

    def request(self, endpoint: str = None, data = None, *, method = None, params: dict = None, headers: MutableMapping[str,str] = None, return_headers = False, content_type: str = None, content_length: int = None, content_filename: str = None):
        url = self.prepare_url(endpoint, params=params)

        all_headers = self.get_request_headers(url)
        if headers:
            for key, value in headers.items():
                all_headers[key] = value
                if key == 'Content-Type' and not content_type:
                    content_type = value
                elif key == 'Content-Length' and content_length is None:
                    content_length = int(value) if isinstance(value, str) else value
                elif key == 'Content-Disposition' and not content_filename:
                    m = re.search(r'attachment\s*;\s*filename\s*=\s*(.+)', value)
                    if m:
                        content_filename = m[1].strip()

        if content_type:
            all_headers['Content-Type'] = content_type
        if content_length is not None:
            all_headers['Content-Length'] = content_length
        if content_filename:
            all_headers['Content-Disposition'] = f"attachment; filename={content_filename}"
                
        if data is not None:
            if not method:
                method = 'POST'

            if isinstance(data, IOBase) or (content_type and not 'application/json' in content_type):
                # keep data as is: this is supposed to be an uploaded file
                if not content_type:
                    content_type = 'application/octet-stream'
            else:
                data = json.dumps(data, ensure_ascii=False, cls=self.json_encoder_cls).encode('utf-8')
            
            self.logger.debug('%s %s', method, url)
            request = Request(url,
                method=method,
                headers=all_headers,
                data=data,
            )
        else:
            if not method:
                method = 'GET'
            
            self.logger.debug('%s %s', method, url)
            request = Request(url,
                method=method,
                headers=all_headers,
            )

        response_headers = {}
        try:
            response: HTTPResponse
            with urlopen(request, timeout=self.timeout) as response:
                response_headers = response.headers
                if self.logger.isEnabledFor(logging.DEBUG):
                    content_type = response.headers.get('content-type', '-')
                    self.logger.debug('%s %s %s %s', response.status, url, response.length, content_type)
                decoded_response = self.decode_response(response)
            
            if return_headers:
                return decoded_response, response.headers
            else:
                return decoded_response
            
        except HTTPError as error:
            with error:
                http_data = self.decode_response(error)
            built_error = self.build_client_error(error, http_data)
        except URLError as error:
            built_error = self.build_client_error(error, None)

        if isinstance(built_error, Exception):
            raise built_error from None
        else:
            if return_headers:
                return built_error, response_headers
            else:
                return built_error


    def prepare_url(self, endpoint: str, *, params: dict = None, base_url: str = None):
        if endpoint is None:
            endpoint = ''

        if not base_url and self.base_url:
            base_url = self.base_url

        if '://' in endpoint or not base_url:
            url = endpoint
            
        else:            
            if endpoint.startswith('/'):
                if base_url.endswith('/'):                    
                    endpoint = endpoint[1:]
            else:
                if not base_url.endswith('/') and endpoint:
                    endpoint = f'/{endpoint}'
            
            if self.force_trailing_slash and not endpoint.endswith('/'):
                endpoint = f'{endpoint}/'

            url = f'{base_url}{endpoint}'

        if params:
            url += "?" + urlencode(params)
        
        return url
    

    def get_request_headers(self, url: str) -> MutableMapping[str,str]:
        headers = {**self.default_headers}
        return headers


    def decode_response(self, response: HTTPResponse):
        rawdata = response.read()
        try:
            strdata = rawdata.decode('utf-8')
        except UnicodeDecodeError:
            strdata = str(rawdata)
            if self.nonjson_error_maxlen is not None and len(strdata) > self.nonjson_error_maxlen:
                strdata = strdata[0:self.nonjson_error_maxlen] + 'â¦'
            return f"[non-utf-8] {strdata}"
        
        try:
            jsondata = json.loads(strdata, cls=self.json_decoder_cls)
        except json.JSONDecodeError:
            if self.nonjson_error_maxlen is not None and len(strdata) > self.nonjson_error_maxlen:
                strdata = strdata[0:self.nonjson_error_maxlen] + 'â¦'
            return f"[non-json] {strdata}"
        
        return jsondata


    def build_client_error(self, error: URLError, http_data):
        if isinstance(error, HTTPError):
            return ApiClientError(error.reason, code=error.status, code_nature='status', data=http_data)
        else:
            return ApiClientError(error.reason, code=error.errno, code_nature='errno', data=http_data)
        

class ApiClientError(Exception):
    def __init__(self, message: str, *, code: int = None, code_nature = None, data = None):
        self.raw_message = message
        self.code = code
        self.code_nature = code_nature
        self.data = data

        super().__init__(self.raw_to_message())


    def raw_to_message(self):
        message = self.raw_message

        if self.code:
            message = (message + ' ' if message else '') + f"[{self.code_nature or 'code'}: {self.code}]"
        
        if self.data:
            if isinstance(self.data, dict):
                for key, value in self.data.items():
                    message = (message + '\n' if message else '') + f"{key}: {value}"
            else:
                message = (message + '\n' if message else '') + str(self.data)

        return message


#endregion


#region Output

def normalize_out(out: str|Path|IOBase|DbAdapter|Literal[False]|None, *, dir: str|Path|None = None, **params) -> str|IOBase|DbAdapter|None:
    from zut.db import DbAdapter, get_db_adapter

    if out is None or out == 'stdout':
        return sys.stdout
    elif out == 'stderr':
        return sys.stderr
    elif out == 'stdin':
        return sys.stdin
    elif out is False:
        return False
    elif isinstance(out, IOBase):
        return out
    elif isinstance(out, (str,Path)):
        is_url = False
        if isinstance(out, str):
            if '://' in out:
                is_url = True
        else:
            out = str(out)
        
        out = out.format(**params)
        if is_url:
            return get_db_adapter(out)

        if dir and not out.startswith(('./', '.\\')):
            out = os.path.join(str(dir), out)
        return os.path.expanduser(out)
    elif isinstance(out, DbAdapter):
        return out
    else:
        raise TypeError(f"Invalid type for out: {type(out)}")


def out_file(out: str|Path|IOBase|Literal[False] = None, *, title: str|Literal[False] = None, dir: str|Path|None = None, append: bool = False, encoding: str = 'utf-8-sig', atexit: bool|Callable = None, **params):
    out = normalize_out(out, title=title, dir=dir, **params)
    return OutFile(out, title=title, append=append, encoding=encoding, atexit=atexit)


def out_table(out: str|Path|IOBase|DbAdapter|Literal[False] = None, *, headers: list[Header|str] = None, tablefmt: Literal['csv','csv-excel','tabulate','excel'] = None, csv_decimal_separator: str = None, csv_delimiter: str = None, csv_quotechar: str = None, csv_nullval: str = None, tz: tzinfo|str|Literal['localtime']|None = None, after1970: bool = None, title: str|Literal[False] = None, dir: str|Path|None = None, append: bool = False, encoding: str = 'utf-8-sig', atexit: bool|Callable = None, **params):
    out = normalize_out(out, title=title, dir=dir, **params)
    return OutTable(out, headers=headers, tablefmt=tablefmt, csv_decimal_separator=csv_decimal_separator, csv_delimiter=csv_delimiter, csv_quotechar=csv_quotechar, csv_nullval=csv_nullval, tz=tz, after1970=after1970, title=title, append=append, encoding=encoding, atexit=atexit)


class OutFile:
    _atexit: list[OutFile] = []

    def __init__(self, out: str|Path|IOBase|Literal[False], *, title: str|Literal[False] = None, append: bool = False, encoding: str = 'utf-8-sig', atexit: bool|Callable = None):
        self.out = out
        self.title = title

        self._append = None
        self.encoding = encoding
        if self.out is False:
            self.out_name = '<null>'
            self.title = False
        elif isinstance(self.out, IOBase):
            self.out_name = getattr(self.out, 'name', f'<{type(self.out).__name__}>')
        else:
            if isinstance(self.out, str):
                self.out_name = self.out
            elif isinstance(self.out, Path):
                self.out_name = str(self.out)
            else:
                raise TypeError(f"Invalid type for out: {type(out)}")
            self._append = append
        
        self.atexit = atexit

        # managed in `file` property
        self._file: IOBase = None
        self._must_close_file: bool = None
     
        self.logger = logging.getLogger(f'{self.__class__.__module__}.{self.__class__.__qualname__}')


    def __enter__(self):
        if self.atexit:
            if callable(self.atexit):
                self.atexit(self)
            else:
                if not self.__class__._atexit:
                    atexit.register(self.__class__._close_atexit)
                self.__class__._atexit.append(self)
        
        if self.title is not False:
            logger.info(f"{'Append' if self._append else 'Export'}{f' {self.title}' if self.title else ''} to {self.out_name}")

        return self
            
    
    def __exit__(self, exc_type = None, exc_val = None, exc_tb = None):        
        if not self.atexit:
            self.close()


    @property
    def file(self):
        if self._file is None:
            if not self.out:
                return None
                
            if isinstance(self.out, IOBase):
                self._file = self.out
                self._must_close_file = False
        
            else:
                from zut import files

                parent = files.dirname(self.out)
                if parent and not files.exists(parent):
                    files.makedirs(parent)

                self._file = self._open_file()
                self._must_close_file = True      
        return self._file
    

    def _open_file(self):
        from zut import files
        return files.open(self.out, 'a' if self._append else 'w', newline='', encoding=self.encoding)


    def close(self):
        self._before_close_file()
        self._close_file()


    def _before_close_file(self):
        pass


    def _close_file(self):
        if self._file and self._must_close_file:
            self._file.close()


    @classmethod
    def _close_atexit(cls):
        from zut.excel import ExcelWorkbook

        # First, perform pre-closing (e.g. exporting data)
        for instance in cls._atexit:
            instance._before_close_file()

        # Then, close the file
        # Cannot be done before, because several OutTable instances may export to the same file
        any_excel = False
        for instance in cls._atexit:
            if isinstance(instance, OutTable) and instance.tablefmt == 'excel':
                any_excel = True
            else:
                instance._close_file()

        if any_excel:
            ExcelWorkbook.close_all_cached()


class OutTable(OutFile):
    DEFAULT_EXCEL_ATEXIT = False
    DEFAULT_CSV_FMT = 'csv'
    DEFAULT_AFTER1970 = False

    def __init__(self, out: str|Path|IOBase|DbAdapter|Literal[False], *, headers: list[Header|str] = None, title: str|Literal[False] = None, tablefmt: Literal['csv','csv-excel','tabulate','excel'] = None, csv_decimal_separator: str = None, csv_delimiter: str = None, csv_quotechar: str = None, csv_nullval: str = None, tz: tzinfo|str|Literal['localtime']|None = None, after1970: bool = None, append: bool = False, encoding: str = 'utf-8-sig', atexit: bool|Callable = None):
        from zut.db import DbAdapter

        if isinstance(out, DbAdapter):
            self.db = out
            out = StringIO()
            if not self.db.table:                
                raise ValueError(f"Invalid db target: table name not provided")
        else:
            self.db = None
        
        super().__init__(out, title=title, append=append, encoding=encoding, atexit=atexit)

        if self.db:
            self.out_name = self.db.get_url(hide_password=True)

        self.headers: list[Header] = headers  # for CSV, not None <=> export started

        if self.db:
            if tablefmt and tablefmt != 'csv':
                raise ValueError(f"Tablefmt \"{tablefmt}\" cannot be used for a database output")
            if csv_decimal_separator and csv_decimal_separator != '.':
                raise ValueError(f"CSV decimal separator \"{csv_decimal_separator}\" cannot be used for a database output")
            self.tablefmt = 'csv'
            csv_decimal_separator = '.' # only this decimal separator is understood by Pg COPY command
        elif not self.out:
            self.tablefmt = None
        elif tablefmt is not None:
            self.tablefmt = tablefmt
        else:
            if isinstance(self.out, IOBase):
                self.tablefmt = 'tabulate' if tabulate is not None and self.out == sys.stdout or self.out == sys.stderr else self.DEFAULT_CSV_FMT
            else:
                from zut.excel import is_excel_path, openpyxl
                self.tablefmt = 'excel' if openpyxl and is_excel_path(self.out, accept_table_suffix=True) else self.DEFAULT_CSV_FMT

        
        self.tz = tz
        self.after1970 = after1970 if after1970 is not None else self.DEFAULT_AFTER1970

        if self.tablefmt == 'excel':
            from zut.excel import split_excel_path
            self.out, self.excel_table_name = split_excel_path(self.out, default_table_name='Out')
            self.out_name = str(self.out) + f'#{self.excel_table_name}'
            if self.atexit is None and self.DEFAULT_EXCEL_ATEXIT:
                self.atexit = True

            self._excel_table: ExcelTable = None

        elif self.tablefmt and self.tablefmt.startswith('csv'):
            self.csv_decimal_separator, self.csv_delimiter, self.csv_quotechar, self.csv_nullval = _get_csv_params(csv_decimal_separator, csv_delimiter, csv_quotechar, csv_nullval, context=self.tablefmt)
            
            self._csv_need_newline = False

        self.row_count = 0
        self._prepared_row_count = 0
     
        self._export_started = False
        self._delayed_rows: list[Iterable] = []
        self._reordering: list[int] = None
        self._reordering_default: list|None = None


    def __enter__(self):
        super().__enter__()
        
        if self.headers: # ensure all headers are of type Header
            actual_headers = []
            for header in self.headers:            
                if not isinstance(header, Header):
                    header = Header(str(header), dict_key=header)
                actual_headers.append(header)
            self.headers = actual_headers
            
        if not self.out:
            pass
        elif self.tablefmt.startswith('csv') and self.headers is not None:
            self._export_started = True
            self._export_headers()
        
        return self
        

    def _open_file(self):
        if self.tablefmt == 'excel':
            from zut.excel import ExcelWorkbook
            return ExcelWorkbook.get_or_create_cached(self.out)
        else:
            if self.db and not self._append:
                logger.debug(f"Truncate table %s.%s", self.db.schema, self.db.table)
                self.db.truncate_table()

            return super()._open_file()


    @property
    def excel_table(self):
        if self._excel_table is None:
            self._excel_table = self.file.get_table(self.excel_table_name, default=None)
            if not self._excel_table:
                self._excel_table = self.file.create_table(self.excel_table_name, no_headers=True if not self.headers else False)
            
            if not self._append:
                self._excel_table.truncate()
        
        return self._excel_table


    def _before_close_file(self):
        if not self.out:
            pass
        elif self.tablefmt == 'tabulate':
            self._export_tabulate()
        else:
            if not self._export_started:
                self._export_started = True
                self._export_headers()
            
            for row in self._delayed_rows:
                self._export_row(row)

            if self.tablefmt.startswith('csv'):
                if (self.headers or self.row_count > 0) and (self.out == sys.stdout or self.out == sys.stderr) and self.out.isatty():
                    # final newline (should be added only on terminal but not in files)
                    self.file.write(os.linesep)
            
            if self.db:
                self._export_db()
                self.db.close()

        if self.title is not False:
            logger.info(f"{self.row_count:,} row{'s' if self.row_count > 1 else ''} {'appended' if self._append else 'exported'} to {self.out_name}")

        self._delayed_rows = [] # clean memory


    def append(self, row):        
        self.row_count += 1

        if not self.out:
            pass
        else:
            if self._export_started:
                self._export_row(row)
            else:
                self._delayed_rows.append(row)


    def _prepare_headers(self):
        if not self.headers:
            dict_headers: dict[str,Header] = {}
            for row in self._delayed_rows:
                if isinstance(row, dict):
                    for key in row:
                        if not key in dict_headers:
                            dict_headers[key] = Header(str(key), dict_key=key)

            self.headers = list(dict_headers.values()) if dict_headers else []


    def _prepare_row(self, row):
        self._prepared_row_count += 1

        if isinstance(row, dict):
            prepared_row = []
            remaining_keys = set(row.keys())
            for i, header in enumerate(self.headers):
                if header.dict_key is not None and  header.dict_key in row:
                    value = row[header.dict_key]
                    remaining_keys.remove(header.dict_key)
                else:
                    value = None
                prepared_row.append(self._prepare_row_value(value, header=header))

            column = len(self.headers) + 1
            for key in remaining_keys:
                self.logger.warning(f"Row {self._prepared_row_count} key \"{key}\" not found in headers: value will be appended at column {column} with an empty header")
                prepared_row.append(self._prepare_row_value(row[key], header=header))
                column += 1
        
        else:
            headers_len = len(self.headers)
            row_len = len(row)    
            if headers_len > 0 and row_len != headers_len:
                self.logger.warning(f"Row {self._prepared_row_count} length: {row_len} (expected headers length: {headers_len})")
             
            prepared_row = []       
            for i, value in enumerate(row):
                header = self.headers[i] if i < headers_len else None
                prepared_row.append(self._prepare_row_value(value, header=header))

        return prepared_row
    

    def _prepare_row_value(self, value, *, header: Header|None, depth=0):
        """
        Prepare value for display.

        NOTE: we don't transform everything in strings, because the underlying output system may take into account the actual type (example: tabulate will align numeric values specifically).
        """
        if header:
            value = header.convert(value, tablefmt=self.tablefmt, after1970=self.after1970)

        if value is None:
            return None
        
        elif isinstance(value, bool):
            if self.tablefmt.startswith('csv'):
                return 'true' if value else 'false'
            return value

        elif isinstance(value, (Decimal,float)):
            if self.tablefmt.startswith('csv'):
                if header:
                    value = format(value, header._get_csv_floatfmt())
                if self.csv_decimal_separator != '.':
                    value = str(value).replace('.', self.csv_decimal_separator)
            return value
        
        elif isinstance(value, (datetime,time)):
            if self.tablefmt == 'excel' or self.tablefmt == 'csv-excel':
                # Excel does not support timezones and microseconds
                if value.tzinfo:
                    value = make_naive(value, self.tz)
                if value.microsecond:
                    value = value.replace(microsecond=0)
            return value

        elif isinstance(value, Enum):
            return value.name
        
        elif isinstance(value, (list,tuple)):            
            # Try to display as a list of elements separated by "|"
            if depth == 0 and _is_iterable_of(value, (str,int,float,Decimal,bool,type(None),date,datetime,time,dict)):
                if len(value) == 0:
                    return None
                
                parts = []
                for element in value:
                    if element is None:
                        part = ''
                    else:                      
                        part = self._prepare_row_value(element, header=header, depth=depth + 1)                        
                        if isinstance(part, str) and '|' in part:                            
                            return str(value) # cancel
                            
                    parts.append(part)

                if len(parts) == 1:
                    return parts[0] # keep original type
                else:
                    return '|'.join(str(part) for part in parts)
            
            return str(value)
        
        elif isinstance(value, dict):
            return str(value)
        
        return value
    
        
    def _export_headers(self):
        self._prepare_headers()

        if self.tablefmt == 'excel':
            existing_headers = self._get_existing_excel_headers()    
        elif self.tablefmt.startswith('csv'):
            if self.db:
                if self.headers:
                    self._write_headers()
                else:                    
                    raise ValueError(f"Cannot export rows to database: no headers")
                return
            else:
                if not self._append:
                    if self.headers:
                        self._write_headers()
                    return            
                existing_headers = self._get_existing_csv_headers()
        else:
            raise NotImplementedError()
        
        if not self.headers and existing_headers:
            raise ValueError(f"Cannot append without explicit headers: existing table contains headers: {', '.join(existing_headers)}")
    
        if not existing_headers:
            if self.headers:
                self._write_headers()
            return

        if existing_headers == self.headers:
            return

        self._reordering = []
        self._reordering_default = [None] * len(existing_headers)
        additional_headers = []
        for header in self.headers:
            try:
                index = existing_headers.index(header.name)
                self._reordering.append(index)
            except ValueError:
                self._reordering_default.append(None)
                index = len(self._reordering_default) - 1
                self._reordering.append(index)
                additional_headers.append(header.name)

        if additional_headers:
            self._append_headers(additional_headers)


    def _export_row(self, row: Iterable):
        if not self._export_started:
            self._export_started = True
            self._export_headers()

        row = self._prepare_row(row)

        if self._reordering:
            new_row = list(self._reordering_default)
            for i, value in enumerate(row):
                if i < len(self._reordering):
                    index = self._reordering[i]
                    new_row[index] = value
                else:
                    new_row.append(value)
            row = new_row
        
        if self.tablefmt == 'excel':
            self._write_excel_row(row)
        elif self.tablefmt.startswith('csv'):
            self._write_csv_row(row)
        else:
            raise NotImplementedError()
    

    def _write_headers(self):        
        if self.tablefmt == 'excel':
            for header in self.headers:
                self.excel_table.insert_col(header.name)
        elif self.tablefmt.startswith('csv'):
            self._write_csv_row(self.headers)
        else:
            raise NotImplementedError()
    

    def _append_headers(self, additional_headers: list[str]):
        if self.tablefmt == 'excel':
            for header in additional_headers:
                self.excel_table.insert_col(header)
        else:
            headers_str = ', '.join(f'"{header}"' for header in additional_headers)
            self.logger.warning(f"Header {headers_str} not found in existing headers: values will be appended without a column header")
            
    
    #region Tabulate specifics

    def _export_tabulate(self):
        self._prepare_headers()
        
        rows = []
        for row in self._delayed_rows:
            prepared_row = self._prepare_row(row)
            for i, value in enumerate(prepared_row):
                header = self.headers[i] if i < len(self.headers) else None
                prepared_row[i] = self._escape_tabulate_value(value, header=header)
            rows.append(prepared_row)
        
        if self.headers:
            floatfmts = []
            for header in self.headers:
                floatfmts.append(header._get_tabulate_floatfmt())
            result = tabulate(rows, headers=self.headers, floatfmt=tuple(floatfmts))
        else:
            result = tabulate(rows)
        
        print(result, file=self.file)


    def _escape_tabulate_value(self, value: str, *, header: Header|None):
        if header and header.max_length is not None:
            if not isinstance(value, str):
                return value
            
            if len(value) > header.max_length:
                part1 = value[0:header.max_length//2]
                part2 = value[len(value) - header.max_length//2 + (1 if header.max_length % 2 == 0 else 0):]
                return part1 + 'â¦' + part2
    
        return value
    
    #endregion

    
    #region Excel specifics
    
    def _get_existing_excel_headers(self):
        return self.excel_table.column_names if self.excel_table.has_headers else []


    def _write_excel_row(self, row):
        table_row = self.excel_table.insert_row()
        
        for i, value in enumerate(row):
            if value is None:
                # keep default formula if any (applied during table.erase_cell(), called from table.insert_row())
                continue
            
            if i < len(table_row):            
                table_row[i] = value
            else:
                logger.warning(f'Ignore values from index {i} ({value})')
                break

    #endregion

    
    #region CSV specifics
    
    def _get_existing_csv_headers(self):
        if not self._append:
            return None

        from zut import files
        
        if not files.exists(self.out):
            return []
        
        with files.open(self.out, 'r', newline='', encoding=self.encoding) as fp:
            if self.encoding == 'utf-8':
                skip_utf8_bom(fp)
                
            reader = csv.reader(fp, delimiter=self.csv_delimiter, quotechar=self.csv_quotechar)
            try:
                result = next(reader)                
                self._csv_need_newline = True
                return result
            except StopIteration:
                return []


    def _write_csv_row(self, row):
        if self._csv_need_newline:
            # CSV newline is standardized for all platforms to '\r\n' as recommended by RFC 4180 (see https://www.rfc-editor.org/rfc/rfc4180#section-2)
            # NOTE: when writing to piped stdout or stderr on Windows, we need to use '\n' (which will be converted to '\r\n' automatically) otherwise an additional empty newline is added
            if sys.platform == 'win32' and (self.out == sys.stdout or self.out == sys.stderr) and not self.out.isatty():
                self.file.write('\n') 
            else:
                self.file.write('\r\n') 

        for i, value in enumerate(row):
            if i > 0:
                self.file.write(self.csv_delimiter)
            self.file.write(self._escape_csv_value(value))
        self.file.flush()

        self._csv_need_newline = True
   

    def _escape_csv_value(self, value: str):
        if value is None:    
            return self.csv_nullval
        if not isinstance(value, str):
            value = str(value)
        if value == '':
            return f'{self.csv_quotechar}{self.csv_quotechar}'

        need_escape = False
        result = ''
        for c in value:
            if c == self.csv_delimiter:
                result += c
                need_escape = True
            elif c == self.csv_quotechar:
                result += f'{c}{c}'
                need_escape = True
            elif c == '\n' or c == '\r':
                result += c
                need_escape = True
            else:
                result += c

        if need_escape:
            result = f'{self.csv_quotechar}{result}{self.csv_quotechar}'
        else:
            result = result

        return result
    
    #endregion


    #region DB specifics
            
    def _export_db(self):                        
        logger.debug(f"Copy data to table %s.%s", self.db.schema, self.db.table)
        self.out.seek(0)
        self.db.load_from_csv(self.out, columns=[header.name for header in self.headers], encoding=self.encoding, csv_delimiter=self.csv_delimiter, csv_quotechar=self.csv_quotechar, csv_nullval=self.csv_nullval)

    #endregion


class Header:
    def __init__(self, name: str|None, *, dict_key: Any = None, max_length: int = None, fmt: str|Callable = None, multiply: int = None):
        """
        :param max_width: applies only for tabulate format, on strings (or dicts or lists converted to strings).
        """
        if name is not None and not isinstance(name, str):
            raise TypeError(f"Invalid type for \"name\": {type(name)}")

        self.name = name

        if dict_key is not None:
            self.dict_key = dict_key
        elif name is not None:
            self.dict_key = name
        else:
            self.dict_key = None

        self.max_length = max_length
        self.fmt = fmt
        self.multiply = multiply

    def __repr__(self):
        return self.name

    def __str__(self):
        return self.name
    
    def _get_csv_floatfmt(self):
        if self.fmt in ['gib']:
            return '.9f'
        elif self.fmt in ['mib']:
            return '.6f'
        elif self.fmt in ['kib']:
            return '.3f'
        else:
            return 'g'
    
    def _get_tabulate_floatfmt(self):
        if self.fmt in ['gib', 'mib', 'kib']:
            return '.2f'
        else:
            return 'g'
        
    def convert(self, value, *, tablefmt: str = None, after1970: bool = False):
        if value is None:
            return None
        
        if after1970 and isinstance(value, datetime) and value.year <= 1970:
            return None
        
        if isinstance(self.fmt, str):
            if self.fmt == 'gib':
                if not isinstance(value, int):
                    value = convert_to_int(value)
                value = gigi_bytes(value)
            
            elif self.fmt == 'mib':
                if not isinstance(value, int):
                    value = convert_to_int(value)
                value = megi_bytes(value)
            
            elif self.fmt == 'kib':
                if not isinstance(value, int):
                    value = convert_to_int(value)
                value = kili_bytes(value)
            
            elif self.fmt == 'human_bytes':
                if not isinstance(value, int):
                    value = convert_to_int(value)
                if tablefmt != 'excel':
                    value = human_bytes(value)
        
            elif self.fmt == 'datetime' or self.fmt == 'dateortime' or self.fmt == 'datetime1970' or self.fmt == 'dateortime1970':
                if not isinstance(value, datetime):
                    value = convert_to_datetime(value)
                if value.year <= 1970 and (after1970 or self.fmt == 'datetime1970' or self.fmt == 'dateortime1970'):
                    value = None
                if tablefmt and tablefmt != 'excel' and self.fmt == 'dateortime':
                    value = value.strftime('%H:%M:%S') if value.date() == today() else value.strftime('%Y-%m-%d')

        elif callable(self.fmt):
            if self.fmt in {bool, int, float, Decimal, datetime, date, time, list}:
                value = convert(value, self.fmt)
            else:
                value = self.fmt(value)

        if self.multiply is not None:
            value = value * self.multiply
    
        return value


def _is_iterable_of(iterable: Iterable, element_type: type|tuple[type]):
    for element in iterable:
        if not isinstance(element, element_type):
            return False        
    return True


#endregion


#region Colors

class Color:
    RESET = '\033[0m'

    BLACK = '\033[0;30m'
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[0;33m'
    BLUE = '\033[0;34m'
    PURPLE = '\033[0;35m'
    CYAN = '\033[0;36m'
    WHITE = '\033[0;37m'

    GRAY = '\033[0;90m'

    # Disable coloring if environment variable NO_COLOR is set to 1
    NO_COLOR = False
    if (os.environ.get('NO_COLOR') or '0').lower() in ['1', 'yes', 'true', 'on']:
        NO_COLOR = True
        for _ in dir():
            if isinstance(_, str) and _[0] != '_' and _ not in ['DISABLED']:
                locals()[_] = ''

    # Set Windows console in VT mode
    if not NO_COLOR and sys.platform == 'win32':
        _kernel32 = ctypes.windll.kernel32
        _kernel32.SetConsoleMode(_kernel32.GetStdHandle(-11), 7)
        del _kernel32

#endregion


#region Errors

class MessageError(ValueError):
    """
    An error that should result to only an error message being printed on the console, without a stack trace.
    """
    pass


def check_completed_subprocess(cp: CompletedProcess, logger: logging.Logger = None, *, label: str = None, level: int|str = None, accept_returncode: int|list[int]|bool = False, accept_stdout: bool = False, accept_stderr: bool = False, maxlen: int = 200):
    """
    Improve message in case of subprocess error, to ease debugging.
    """
    if not label:
        label = cp.args[0]

    if not logger and level is not None:
        logger = globals()["logger"]
    elif logger and level is None:
        level = logging.ERROR


    def is_returncode_issue(returncode: int):
        if accept_returncode is True:
            return False
        elif isinstance(accept_returncode, int):
            return returncode != accept_returncode
        elif isinstance(accept_returncode, (list,tuple)):
            return returncode not in accept_returncode
        else:
            return returncode != 0
    

    def extract_stream(content: str|bytes|None, name: str, color: str):
        if content is None:
            return None
        elif not isinstance(content, str):
            try:
                content = content.decode('utf-8')
            except UnicodeDecodeError:
                content = content.decode('cp1252')
        
        data = content.strip()
        if maxlen and len(data) > maxlen:
            data = data[0:maxlen] + 'â¦'

        result = ''
        for line in data.splitlines():
            result += f"\n{color}[{label} {name}]{Color.RESET} {line}"
        return result
    

    issue = False

    if is_returncode_issue(cp.returncode):
        message = f"{label} returned {Color.YELLOW}code {cp.returncode}{Color.RESET}"
        issue = True
    else:
        message = f"{label} returned {Color.CYAN}code {cp.returncode}{Color.RESET}"
    

    result = extract_stream(cp.stdout, 'stdout', Color.CYAN if accept_stdout else Color.YELLOW)
    if result:
        message += result
        if not accept_stdout:
            issue = True

    result = extract_stream(cp.stderr, 'stderr', Color.CYAN if accept_stderr else Color.YELLOW)
    if result:
        message += result
        if not accept_stderr:
            issue = True

    if issue:
        if logger:
            logger.log(level, message)
        else:
            raise SubprocessError(message)
    else:
        if logger:
            logger.log(logging.DEBUG, message)

    return issue

#endregion


#region Commands
    
def add_func_command(subparsers: _SubParsersAction[ArgumentParser], handle: FunctionType, add_arguments: FunctionType = None, *, name: str = None, doc: str = None, **defaults):
    """
    Add the given function as a subcommand of the parser.
    """
    if add_arguments is None:
        add_arguments = getattr(handle, 'add_arguments', None)
    
    if name is None:
        name = handle.__name__
    
    if doc is None:
        doc = handle.__doc__
        add_doc = getattr(handle, 'add_doc', None)
        if add_doc:
            doc = (doc if doc else '') + add_doc()

    cmdparser = subparsers.add_parser(name, help=get_help_text(doc), description=get_description_text(doc) if doc else None, formatter_class=RawTextHelpFormatter)
    cmdparser.set_defaults(handle=handle, **defaults)

    if add_arguments:
        add_arguments(cmdparser)

    return cmdparser


def add_module_command(subparsers: _SubParsersAction[ArgumentParser], module: str|ModuleType, *, name: str = None, doc: str = None, **defaults):
    """
    Add the given module as a subcommand of the parser.
    """
    if not isinstance(module, ModuleType):
        module = import_module(module)

    if name is None:
        module_basename = module.__name__.split('.')[-1]
        name = module_basename.split('.')[-1]
        if name.endswith('cmd') and len(name) > len('cmd'):
            name = name[0:-len('cmd')]

    if hasattr(module, 'Command'): # like Django management command
        cmdcls = module.Command
        handle = cmdcls  # use the Command class as "handle" - The runner will have to instanciate the class and call the class' handle.
        add_arguments = getattr(cmdcls, 'add_arguments', None)
        if doc is None:
            doc = getattr(cmdcls, 'help', None) or cmdcls.__doc__

    else:
        try:
            handle = getattr(module, 'handle')
        except AttributeError:
            try:
                handle = getattr(module, name)
            except AttributeError:
                handle = None
        
        if not handle:
            raise ValueError(f"cannot use module {module.__name__} as a command: no function named 'handle' or '{name}'")
        add_arguments = getattr(module, 'add_arguments', None)
        
    if doc is None and module.__doc__:
        doc = module.__doc__
    
    add_func_command(subparsers, handle, add_arguments, name=name, doc=doc, **defaults)


def add_package_commands(subparsers: _SubParsersAction[ArgumentParser], package: str):
    """
    Add all modules in the given package as subcommands of the parser.
    """
    package_spec = find_spec(package)
    if not package_spec:
        raise KeyError(f"package not found: {package}")
    if not package_spec.origin:
        raise KeyError(f"not a package: {package} (did you forget __init__.py ?)")
    package_path = Path(package_spec.origin).parent
    
    for module_path in sorted(package_path.iterdir()):
        if module_path.is_dir() or module_path.name.startswith("_") or not module_path.name.endswith(".py"):
            continue

        module = module_path.stem
        add_module_command(subparsers, f"{package}.{module}")


def get_help_text(docstring: str):
    if docstring is None:
        return None
    
    docstring = docstring.strip()
    try:
        return docstring[0:docstring.index('\n')].strip()
    except:
        return docstring
    

def get_description_text(docstring: str):
    if docstring is None:
        return None
    
    return dedent(docstring)


def get_exit_code(return_value: Any) -> int:
    if not isinstance(return_value, int):
        return_value = 0 if return_value is None or return_value is True else 1
    return return_value


def exec_command(handle: Callable, args: dict):
    if not handle:
        logger.error("No command given")
        return 1

    try:
        r = handle(**args)
        r = get_exit_code(r)
    except MessageError as err:
        logger.error(str(err))
        r = 1
    except BaseException as err: # including KeyboardInterrupt
        message = str(err)
        logger.exception(f"Exiting on {type(err).__name__}{f': {message}' if message else ''}")
        r = 1

    sys.exit(r)


#endregion


#region Config

_configs: dict[Path,ExtendedConfigParser] = {}

def get_config(prog: ModuleType|str|Path, *, if_none: Literal['warn'] = None):
    prog_root = _get_module_root(prog)
    config = _configs.get(prog_root)

    if config:
        return config
    
    else:
        config = ExtendedConfigParser()
        _configs[prog_root] = config

        paths = get_config_paths(prog_root, '.conf', if_exist=True)
        if paths:
            for path in paths:
                logger.debug("Config file: %s", path)
            config.read(paths)
        else:
            if if_none == 'warn':
                logger.warning("No config file found")

        return config


def get_config_paths(prog: ModuleType|str|Path, name: str = None, *, if_exist: bool = False):
    prog_root = _get_module_root(prog)
    prog_name = prog_root.name.replace('_', '-')

    if name is None:
        name = '' # will point on config directories
    elif name.startswith('.'):
        name = f"{prog_name}{name}"
    
    possible_paths = [
        prog_root.joinpath('config', name),
        Path(os.environ.get('ProgramData', 'C:\\ProgramData' if sys.platform == 'win32' else '/etc')).joinpath(prog_name, name),
        Path(os.environ.get('LOCALAPPDATA', '~\\AppData\\Local' if sys.platform == 'win32' else '~/.config')).expanduser().joinpath(prog_name, name),
        Path.cwd().joinpath('data', name),
    ]

    if if_exist:
        paths = []
        for path in possible_paths:
            if path.exists():
                paths.append(path)
        return paths
    
    else:
        return possible_paths


def _get_module_root(module: ModuleType|str|Path):
    if isinstance(module, Path):
        path = module
    elif isinstance(module, str):
        if '/' in module or '\\' in module:
            path = Path(module)
        else:
            module = import_module(module)
            path = Path(module.__file__)
    else:
        path = Path(module.__file__)

    if not path.is_dir():
        path = path.parent

    return path


def _get_prog_name(prog: ModuleType|str|Path = None):
    if isinstance(prog, str) and not '/' in prog and not '\\' in prog and not '.' in prog:
        return prog
    module_root = _get_module_root(prog if prog else sys.argv[0])
    return module_root.name.replace('_', '-')


class ExtendedConfigParser(ConfigParser):
    def getlist(self, section: str, option: str, *, raw=False, vars=None, delimiter=None, fallback: list[str] = _UNSET) -> list[str]:
        values_str = self.get(section, option, raw=raw, vars=vars, fallback=fallback)
        if not isinstance(values_str, str):
            return values_str # fallback
    
        if not values_str:
            return []
        
        if delimiter:
            values = values_str.split(delimiter)
        else:
            values = re.split(r'[\W,;|]+', values_str)
        
        result = []
        for value in values:
            value = value.strip()
            if not value:
                continue
            result.append(value)

        return result

#endregion
    

#region Logging

def configure_logging(prog: ModuleType|str|Path = None, *, level: str|int = None, systemd = False, manage_exit = True):
    config = get_logging_dict_config(prog, level=level, systemd=systemd, manage_exit=manage_exit)
    logging.config.dictConfig(config)


def get_logging_dict_config(prog: ModuleType|str|Path = None, *, level: str|int = None, systemd = False, manage_exit = True):
    if isinstance(level, int):
        level = logging.getLevelName(level)
    
    config = {
        'version': 1,
        'disable_existing_loggers': False,
        'formatters': {
            'default': {
                'format': '%(levelname)s [%(name)s] %(message)s',
            },
        },
        'handlers': {
            'console': {
                'class': 'logging.StreamHandler',
                'formatter': 'default',
            },
        },
        'root': {
            'handlers': ['console'],
            'level': level if level else (os.environ.get('LOG_LEVEL', '').upper() or 'INFO'),
        },
        'loggers': {
            'django': { 'level': os.environ.get('DJANGO_LOG_LEVEL', '').upper() or 'INFO', 'propagate': False },
            'smbprotocol': { 'level': 'WARNING' },
        },
    }

    if colorlog and not Color.NO_COLOR:
        config['formatters']['colored'] = {
            '()': 'colorlog.ColoredFormatter',
            'format': '%(log_color)s%(levelname)s%(reset)s %(light_black)s[%(name)s]%(reset)s %(message_log_color)s%(message)s%(reset)s',
            'log_colors': {
                'DEBUG': 'light_black',
                'INFO': 'cyan',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'bg_red',
            },
            'secondary_log_colors': {
                'message': {
                    'DEBUG': 'light_black',
                    'INFO': 'reset',
                    'WARNING': 'yellow',
                    'ERROR': 'red',
                    'CRITICAL': 'red',
                },
            }
        }

        config['handlers']['console']['formatter'] = 'colored'


    log_file = os.environ.get('LOG_FILE', None)
    if log_file:
        if log_file.lower() in ['1', 'true', 'yes', 'on']:
            log_file = f"{_get_prog_name(prog)}.log"

        config['formatters']['file'] = {
            'format': '%(asctime)s %(levelname)s [%(name)s] %(message)s',
        }

        config['handlers']['file'] = {
            'class': 'logging.FileHandler',
            'formatter': 'file',
            'filename': log_file,
            'mode': 'a',
        }

        config['root']['handlers'].append('file')
    

    if systemd and sys.platform != 'win32':
        config['formatters']['systemd'] = {
            'format': '%(levelname)s [%(name)s] %(message)s',
        }

        config['handlers']['systemd'] = {
            'class': 'systemd.journal.JournalHandler',
            'formatter': 'systemd',
            'SYSLOG_IDENTIFIER': _get_prog_name(prog),
        }

        config['root']['handlers'].append('systemd')

    
    if manage_exit:
        config['handlers']['exit'] = {
            'class': ExitHandler.__module__ + '.' + ExitHandler.__qualname__,
            'level': 'WARNING',
        }

        config['root']['handlers'].append('exit')

    return config


class ExitHandler(logging.Handler):
    """
    A logging handler that counts warnings and errors.
    
    If warnings and errors occured during the program execution, display counts at exit
    and set exit code to 68 (EADV) (if it was not explicitely set with `sys.exit` function).
    """
    _counts: dict[int, int] = {}
    _detected_exception: tuple[type[BaseException], BaseException, TracebackType|None] = None
    _detected_exit_code = 0

    _original_exit = sys.exit
    _original_excepthook = sys.excepthook

    _already_registered = False

    def __init__(self):
        if not self.__class__._already_registered:
            sys.exit = self.__class__._exit
            sys.excepthook = self.__class__._excepthook
            atexit.register(self.__class__._atexit)
            self.__class__._already_registered = True
        
        super().__init__(level=logging.WARNING)

    def emit(self, record: logging.LogRecord):
        if record.levelno >= self.level:
            if not record.levelno in self.__class__._counts:
                self.__class__._counts[record.levelno] = 1
            else:
                self.__class__._counts[record.levelno] += 1
    
    @classmethod
    def _exit(cls, code: int = 0):
        cls._detected_exit_code = code
        cls._original_exit(code)
    
    @classmethod
    def _excepthook(cls, exc_type: type[BaseException], exc_value: BaseException, exc_traceback: TracebackType|None):
        cls._detected_exception = exc_type, exc_value, exc_traceback
        cls._original_exit(1)

    @classmethod
    def _atexit(cls):
        if cls._detected_exception:
            exc_type, exc_value, exc_traceback = cls._detected_exception

            msg = 'An unhandled exception occured\n'
            msg += ''.join(format_exception(exc_type, exc_value, exc_traceback)).strip()
            logger.critical(msg)

        else:
            level = None
            msg = ''
            
            for levelno in sorted(cls._counts.keys(), reverse=True):
                if level is None:
                    level = levelno
                levelname = logging.getLevelName(levelno)
                msg += (', ' if msg else 'Logged ') + f'{levelname}: {cls._counts[levelno]}'

            if level is not None:
                logger.log(level, msg)
                
                # Change exit code if it was not originally set explicitely to another value, using `sys.exit()`
                if cls._detected_exit_code == 0:
                    os._exit(68) # EADV (Advertise error) = 68

#endregion


#region Files

def configure_smb_credentials(user: str = None, password: str = None):
    global _smb_credentials_configured
    
    from zut.files import _smb_credentials_configured, smbclient

    if user or password:
        if not smbclient:
            raise ValueError(f"Package `smbprotocol` is required to specify smb credentials")
        smbclient.ClientConfig(username=user, password=password)
        _smb_credentials_configured = True

#endregion
